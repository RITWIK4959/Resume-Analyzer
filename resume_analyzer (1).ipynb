{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get The text from the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Using cached pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pytesseract\n",
      "  Using cached pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pdf2image\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pdfminer.six==20250327 (from pdfplumber)\n",
      "  Using cached pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting Pillow>=9.1 (from pdfplumber)\n",
      "  Using cached pillow-11.1.0-cp313-cp313-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Using cached pypdfium2-4.30.1-py3-none-win_amd64.whl.metadata (48 kB)\n",
      "Collecting charset-normalizer>=2.0.0 (from pdfminer.six==20250327->pdfplumber)\n",
      "  Using cached charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20250327->pdfplumber)\n",
      "  Using cached cryptography-44.0.2-cp39-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in .\\.venv\\lib\\site-packages (from pytesseract) (24.2)\n",
      "Collecting cffi>=1.12 (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber)\n",
      "  Using cached cffi-1.17.1-cp313-cp313-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Using cached pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
      "Using cached pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
      "Using cached pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Using cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Using cached pillow-11.1.0-cp313-cp313-win_amd64.whl (2.6 MB)\n",
      "Using cached pypdfium2-4.30.1-py3-none-win_amd64.whl (3.0 MB)\n",
      "Using cached charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Using cached cryptography-44.0.2-cp39-abi3-win_amd64.whl (3.2 MB)\n",
      "Using cached cffi-1.17.1-cp313-cp313-win_amd64.whl (182 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: pypdfium2, pycparser, Pillow, charset-normalizer, pytesseract, pdf2image, cffi, cryptography, pdfminer.six, pdfplumber\n",
      "Successfully installed Pillow-11.1.0 cffi-1.17.1 charset-normalizer-3.4.1 cryptography-44.0.2 pdf2image-1.17.0 pdfminer.six-20250327 pdfplumber-0.11.6 pycparser-2.22 pypdfium2-4.30.1 pytesseract-0.3.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pdfplumber pytesseract pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        # Try direct text extraction\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text\n",
    "\n",
    "        if text.strip():\n",
    "            return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Direct text extraction failed: {e}\")\n",
    "\n",
    "    # Fallback to OCR for image-based PDFs\n",
    "    print(\"Falling back to OCR for image-based PDF.\")\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path)\n",
    "        for image in images:\n",
    "            page_text = pytesseract.image_to_string(image)\n",
    "            text += page_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"OCR failed: {e}\")\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Text from PDF:\n",
      "Gandla Veera Charan\n",
      "§ VeeraCharan222 | (cid:239) Gandla Veera Charan | # gveeracharan@gmail.com | (cid:131) +91 9247156084\n",
      "Work Experience\n",
      "Frontend Developer\n",
      "Apna College Sigma Batch\n",
      "• Developed and optimized front-end components for interactive web applications.\n",
      "• Enhanced user experience through responsive design and efficient JavaScript implementations.\n",
      "Projects\n",
      "Hospital Management System\n",
      "• Designed and implemented a hospital management system with patient records, appointments, and billing features.\n",
      "• Utilized MySQL for data storage and JavaScript for interactive UI components.\n",
      "Blackjack Game (C++)\n",
      "• Designed and implemented a text-based Blackjack game in C++ with complete game logic.\n",
      "• Utilized object-oriented programming principles for game structure and card handling.\n",
      "• Integrated random number generation for realistic card shuffling and gameplay mechanics.\n",
      "Skills\n",
      "• Programming Languages: C, C++, JavaScript, Python\n",
      "• Web Development: HTML, CSS\n",
      "• Databases: MySQL\n",
      "Education\n",
      "SRM University, Andhra Pradesh 2023 – Ongoing\n",
      "Bachelor’s in Computer Science, GPA: 8.62/10\n",
      "IIIT University, RK Valley, Kadapa District\n",
      "Class 12 (CBSE) — CGPA: 8.9 (2022)\n",
      "Good Shepherd E.M School\n",
      "Class 10 (CBSE) — Percentage: 86.2% (2021)\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"charan_resume.pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "print(\"\\nExtracted Text from PDF:\")\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Google GenerativeAI Api Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google.generativeai\n",
      "  Using cached google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google.generativeai)\n",
      "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google.generativeai)\n",
      "  Using cached google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google.generativeai)\n",
      "  Using cached google_api_python_client-2.166.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting google-auth>=2.15.0 (from google.generativeai)\n",
      "  Using cached google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting protobuf (from google.generativeai)\n",
      "  Using cached protobuf-6.30.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting pydantic (from google.generativeai)\n",
      "  Downloading pydantic-2.11.2-py3-none-any.whl.metadata (64 kB)\n",
      "Collecting tqdm (from google.generativeai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions (from google.generativeai)\n",
      "  Downloading typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google.generativeai)\n",
      "  Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google.generativeai)\n",
      "  Using cached googleapis_common_protos-1.69.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting requests<3.0.0,>=2.18.0 (from google-api-core->google.generativeai)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google.generativeai)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google.generativeai)\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google.generativeai)\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic->google.generativeai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic->google.generativeai)\n",
      "  Downloading pydantic_core-2.33.1-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic->google.generativeai)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in .\\.venv\\lib\\site-packages (from tqdm->google.generativeai) (0.4.6)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Using cached grpcio-1.71.0-cp313-cp313-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Using cached grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google.generativeai)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.4.1)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached google_generativeai-0.8.4-py3-none-any.whl (175 kB)\n",
      "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Using cached google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "Using cached google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached google_api_python_client-2.166.0-py2.py3-none-any.whl (13.2 MB)\n",
      "Downloading pydantic-2.11.2-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.1-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 21.1 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.13.1-py3-none-any.whl (45 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Using cached googleapis_common_protos-1.69.2-py3-none-any.whl (293 kB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached grpcio-1.71.0-cp313-cp313-win_amd64.whl (4.3 MB)\n",
      "Using cached grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, uritemplate, typing-extensions, tqdm, python-dotenv, pyparsing, pyasn1, protobuf, idna, grpcio, certifi, cachetools, annotated-types, typing-inspection, rsa, requests, pydantic-core, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, pydantic, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google.generativeai\n",
      "Successfully installed annotated-types-0.7.0 cachetools-5.5.2 certifi-2025.1.31 google-ai-generativelanguage-0.6.15 google-api-core-2.24.2 google-api-python-client-2.166.0 google-auth-2.38.0 google-auth-httplib2-0.2.0 google.generativeai-0.8.4 googleapis-common-protos-1.69.2 grpcio-1.71.0 grpcio-status-1.71.0 httplib2-0.22.0 idna-3.10 proto-plus-1.26.1 protobuf-5.29.4 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.2 pydantic-core-2.33.1 pyparsing-3.2.3 python-dotenv-1.1.0 requests-2.32.3 rsa-4.9 tqdm-4.67.1 typing-extensions-4.13.1 typing-inspection-0.4.0 uritemplate-4.1.1 urllib3-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google.generativeai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY found!\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Debugging: Check if the key is loaded\n",
    "api_key = \"AIzaSyBSe66nRNUzSakt7PcVXaLqhFj2LRL8jws\"\n",
    "if api_key is None:\n",
    "    print(\"Error: GOOGLE_API_KEY is not set!\")\n",
    "else:\n",
    "    print(\"GOOGLE_API_KEY found!\")\n",
    "\n",
    "# Configure genai\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"What is the capital of India?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"The capital of India is **New Delhi**.\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0026347806677222254\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 7,\n",
      "        \"candidates_token_count\": 10,\n",
      "        \"total_token_count\": 17\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-flash\"\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is **New Delhi**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def analyze_resume(resume_text, job_description=None):\n",
    "    if not resume_text:\n",
    "        return json.dumps({\"error\": \"Resume text is required for analysis.\"})\n",
    "    \n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "    base_prompt = f\"\"\"\n",
    "    You are an experienced HR with Technical Experience in one of the following fields: \n",
    "    - Data Science\n",
    "    - Data Analyst\n",
    "    - DevOps\n",
    "    - Machine Learning Engineer\n",
    "    - Prompt Engineer\n",
    "    - AI Engineer\n",
    "    - Full Stack Web Development\n",
    "    - Big Data Engineering\n",
    "    - Marketing Analyst\n",
    "    - Human Resource Manager\n",
    "    - Software Developer\n",
    "\n",
    "    Your task is to **review** the provided resume and determine how well the candidate aligns with these job roles. \n",
    "\n",
    "    - List **skills the candidate already has**.\n",
    "    - Suggest **skills they should improve**.\n",
    "    - Recommend **courses for skill improvement**.\n",
    "    - Highlight **strengths and weaknesses**.\n",
    "\n",
    "    Resume:\n",
    "    {resume_text}\n",
    "    \"\"\"\n",
    "\n",
    "    if job_description:\n",
    "        base_prompt += f\"\"\"\n",
    "        Compare this resume to the **job description**:\n",
    "\n",
    "        **Job Description:**\n",
    "        {job_description}\n",
    "\n",
    "        Provide **strengths, weaknesses, and improvement points** based on the job requirements.\n",
    "        \"\"\"\n",
    "\n",
    "    response = model.generate_content(base_prompt)\n",
    "    analysis = response.text.strip()\n",
    "\n",
    "    return json.dumps({\"success\": True, \"analysis\": analysis}, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"analysis\": \"## Resume Review of Gandla Veera Charan\\n\\n**My Expertise:**  I'm an HR professional with a background in Full Stack Web Development.\\n\\n**Alignment with Job Roles:**  Based on the provided resume, Gandla Veera Charan is a strong candidate for entry-level Front-End Developer roles or Junior roles in related fields.  His skills and experience are less directly applicable to roles like Data Scientist, Machine Learning Engineer, or Big Data Engineer. He also lacks the experience for more senior roles.\\n\\n\\n**Skills the Candidate Already Has:**\\n\\n* **Programming Languages:** C, C++, JavaScript, Python\\n* **Web Development:** HTML, CSS, JavaScript (front-end focus)\\n* **Databases:** MySQL\\n* **Frontend Development:** Experience building interactive web applications, responsive design.\\n* **Object-Oriented Programming (OOP):** Demonstrated in the Blackjack project.\\n* **Project Management:**  Experience managing small-to-medium projects (Hospital Management System, Blackjack Game).\\n\\n\\n**Skills the Candidate Should Improve:**\\n\\n* **Backend Development:**  While his front-end skills are decent, he lacks significant experience in backend technologies.  This severely limits his potential for full-stack roles.\\n* **Version Control (Git):**  Essential for collaborative software development.  No mention of Git on the resume.\\n* **Frameworks/Libraries:** Proficiency in popular JavaScript frameworks like React, Angular, or Vue.js is highly desirable for front-end roles.  Similarly, familiarity with backend frameworks (Node.js, Django, Flask, etc.) would broaden his options.\\n* **Testing & Debugging:**  Strong testing and debugging skills are crucial for any developer.\\n* **Software Design Principles:**  Further development of design patterns and software architecture would be beneficial.\\n* **Data Structures and Algorithms:**  Fundamental to many software engineering roles, especially for more advanced positions.\\n\\n\\n\\n**Recommended Courses for Skill Improvement:**\\n\\n* **Frontend Frameworks:**  A course on React, Angular, or Vue.js.  Platforms like Udemy, Coursera, and freeCodeCamp offer many options.\\n* **Backend Development:**  A course on Node.js, Python (with Django/Flask), or another backend technology.\\n* **Git and GitHub:**  Numerous online resources and tutorials cover Git.\\n* **Testing and Debugging:**  Courses on software testing methodologies and debugging techniques.\\n* **Data Structures and Algorithms:**  Many online courses and books cover this fundamental topic.\\n* **Databases (Advanced):** Explore NoSQL databases like MongoDB or advanced SQL concepts.\\n\\n\\n**Strengths:**\\n\\n* **Diverse Programming Language Skills:**  Proficient in several programming languages, showing adaptability.\\n* **Project Experience:**  Has built two projects demonstrating practical skills, one in web development and another in C++.\\n* **Good Academic Record:**  High GPA and percentage scores indicate strong academic performance.\\n\\n\\n**Weaknesses:**\\n\\n* **Lack of Backend Experience:**  This limits his job prospects to primarily front-end roles.\\n* **Missing Essential Skills:** Absence of Git, testing methodologies, and advanced frameworks limits competitiveness.\\n* **Resume Could Be Improved:** The resume is concise but could be improved with more detail on project accomplishments (e.g., challenges overcome, technologies used, results achieved) and quantifiable results.  Adding a portfolio link would significantly boost the resume's impact.\\n* **Limited Professional Experience:** The Apna College experience, while valuable, is short-term.\\n\\n\\n**Overall:**\\n\\nGandla Veera Charan demonstrates potential as a junior front-end developer.  However, to increase his marketability and open up more career opportunities, he should significantly improve his backend skills, version control knowledge, and familiarize himself with industry-standard frameworks and tools.  Addressing these weaknesses will substantially strengthen his resume and increase his chances of securing a better position.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(analyze_resume(resume_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Using cached streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting flask\n",
      "  Using cached flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Using cached altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in .\\.venv\\lib\\site-packages (from streamlit) (5.5.2)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting numpy<3,>=1.23 (from streamlit)\n",
      "  Using cached numpy-2.2.4-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: packaging<25,>=20 in .\\.venv\\lib\\site-packages (from streamlit) (24.2)\n",
      "Collecting pandas<3,>=1.4.0 (from streamlit)\n",
      "  Using cached pandas-2.2.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in .\\.venv\\lib\\site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in .\\.venv\\lib\\site-packages (from streamlit) (5.29.4)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Using cached pyarrow-19.0.1-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in .\\.venv\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in .\\.venv\\lib\\site-packages (from streamlit) (4.13.1)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Using cached watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in .\\.venv\\lib\\site-packages (from streamlit) (6.4.2)\n",
      "Collecting Werkzeug>=3.1 (from flask)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Jinja2>=3.1.2 (from flask)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting itsdangerous>=2.2 (from flask)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Using cached narwhals-1.33.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: colorama in .\\.venv\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2>=3.1.2->flask)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.24.0-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in .\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Using cached streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
      "Using cached flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Using cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached numpy-2.2.4-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "Using cached pandas-2.2.3-cp313-cp313-win_amd64.whl (11.5 MB)\n",
      "Using cached pyarrow-19.0.1-cp313-cp313-win_amd64.whl (25.2 MB)\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Using cached narwhals-1.33.0-py3-none-any.whl (322 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.24.0-cp313-cp313-win_amd64.whl (239 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pytz, watchdog, tzdata, toml, tenacity, smmap, rpds-py, pyarrow, numpy, narwhals, MarkupSafe, itsdangerous, click, blinker, attrs, Werkzeug, referencing, pandas, Jinja2, gitdb, pydeck, jsonschema-specifications, gitpython, flask, jsonschema, altair, streamlit\n",
      "Successfully installed Jinja2-3.1.6 MarkupSafe-3.0.2 Werkzeug-3.1.3 altair-5.5.0 attrs-25.3.0 blinker-1.9.0 click-8.1.8 flask-3.1.0 gitdb-4.0.12 gitpython-3.1.44 itsdangerous-2.2.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 narwhals-1.33.0 numpy-2.2.4 pandas-2.2.3 pyarrow-19.0.1 pydeck-0.9.1 pytz-2025.2 referencing-0.36.2 rpds-py-0.24.0 smmap-5.0.2 streamlit-1.44.1 tenacity-9.1.2 toml-0.10.2 tzdata-2025.2 watchdog-6.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install streamlit flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask_cors\n",
      "  Using cached flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
      "Requirement already satisfied: flask>=0.9 in .\\.venv\\lib\\site-packages (from flask_cors) (3.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.7 in .\\.venv\\lib\\site-packages (from flask_cors) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in .\\.venv\\lib\\site-packages (from flask>=0.9->flask_cors) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in .\\.venv\\lib\\site-packages (from flask>=0.9->flask_cors) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in .\\.venv\\lib\\site-packages (from flask>=0.9->flask_cors) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in .\\.venv\\lib\\site-packages (from flask>=0.9->flask_cors) (1.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in .\\.venv\\lib\\site-packages (from Werkzeug>=0.7->flask_cors) (3.0.2)\n",
      "Requirement already satisfied: colorama in .\\.venv\\lib\\site-packages (from click>=8.1.3->flask>=0.9->flask_cors) (0.4.6)\n",
      "Using cached flask_cors-5.0.1-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: flask_cors\n",
      "Successfully installed flask_cors-5.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install flask_cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
